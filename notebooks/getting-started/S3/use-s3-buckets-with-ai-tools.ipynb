{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac60a3db-eb56-4fd4-b139-95114faaee64",
   "metadata": {},
   "source": [
    "# Using objects from your S3 buckets in OVHcloud AI Tools\n",
    "\n",
    "This tutorial provides help to manage and use S3 buckets with AI Tools in Python, using the `boto3` library. We will show you how you can interact with your S3 Buckets and files by creating buckets, downloading objects, listing objects and reading their content when working with AI Notebooks, AI Training and AI Deploy.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "To be able to follow this tutorial, you will need to have followed the [Data - S3 compliance with AI Tools documentation](https://help.ovhcloud.com/csm/en-gb-public-cloud-ai-s3-compliance?id=kb_article_view&sysparm_article=KB0058011) first, in particular the following steps:\n",
    "\n",
    "- Have created a S3 user\n",
    "- Checked that this user has ***ObjectStore operator*** and ***AI Training Operator*** rights\n",
    "- Have created a datastore with this user\n",
    "\n",
    "## Code\n",
    "\n",
    "The different steps are as follow:\n",
    "- Setup the environment\n",
    "- Set your S3 datastore\n",
    "- List all S3 buckets in your S3 datastore\n",
    "- Create a new bucket\n",
    "- List all objects of a specific bucket\n",
    "- Read content from objects\n",
    "- Download object from S3 bucket\n",
    "\n",
    "### Setup the environment\n",
    "\n",
    "Let's install the libraries we will need, then import them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f08b37-95cc-42f8-ba68-5e301b9356f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744144e-f580-4131-992f-bf3b71b42121",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a59961-e81c-421c-aa2e-451292f1f9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os \n",
    "import pandas as pd\n",
    "from pathlib import Path "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8347366f-98ec-4f4b-87c8-f53aea2b20e7",
   "metadata": {},
   "source": [
    "### Set your S3 datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc5759-97ce-472c-8c96-cb7224387bcc",
   "metadata": {},
   "source": [
    "To interact with an S3 bucket, we need to initialize a S3 client and configure it with our user credentials (`s3_access_key`, `s3_secret_key`, the `endpoint URL`, and the selected region).\n",
    "\n",
    "***Make sure to replace these credentials by yours.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4af75-3172-4c0f-b8a7-f4d0bcee60f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on the user\n",
    "s3_access_key= \"MY_KEY\" \n",
    "s3_secret_key= \"MY_SECRET\" \n",
    "\n",
    "# Depeding on the region\n",
    "s3_endpoint=\"https://s3.gra.io.cloud.ovh.net/\"\n",
    "s3_region = \"gra\"\n",
    "  \n",
    "s3_client = boto3.client( \n",
    "    \"s3\", \n",
    "    aws_access_key_id=s3_access_key, \n",
    "    aws_secret_access_key=s3_secret_key, \n",
    "    endpoint_url=s3_endpoint,\n",
    "    region_name=s3_region\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a88d2f-5a8a-4c82-a4b3-9fc7b5d24ec1",
   "metadata": {},
   "source": [
    "Once the S3 client has been initialized, we are ready to communicate with the S3-compatible storage service. Many things can be done.\n",
    "\n",
    "### List all S3 buckets in your S3 datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cad01089-952d-4a81-b206-d02a5049d525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing buckets:\n",
      "----------------\n",
      "my-bucket-s3-n2\n",
      "my-bucket-s3-n3\n",
      "my-bucket-s3.0\n"
     ]
    }
   ],
   "source": [
    "response = s3_client.list_buckets()\n",
    "\n",
    "print(f\"Existing buckets:\\n{16 * '-'}\")\n",
    "for bucket in response['Buckets']:\n",
    "    print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee06239-8f19-4858-8a68-9a8c617925e3",
   "metadata": {},
   "source": [
    "### Create a new bucket\n",
    "\n",
    "Let's create a new bucket named `bucketname`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4130ed0a-90c1-48a0-b64a-b908b56e219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3_client.create_bucket(\n",
    "    Bucket='bucketname',\n",
    "    CreateBucketConfiguration={\n",
    "        'LocationConstraint': s3_region,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e228c0a-0956-4462-9304-3dd419ae1a17",
   "metadata": {},
   "source": [
    "List buckets again, to see if the bucket `bucketname` has been created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f642835e-6e66-4e42-81cf-f6249be3bac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucketname\n",
      "my-bucket-s3-n2\n",
      "my-bucket-s3-n3\n",
      "my-bucket-s3.0\n"
     ]
    }
   ],
   "source": [
    "response = s3_client.list_buckets()\n",
    "for bucket in response['Buckets']:\n",
    "    print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293f8a9",
   "metadata": {},
   "source": [
    "*Keep in mind that the bucket name must be between 3 and 63 characters, can consist only of lowercase letters, numbers, dots (.), and hyphens (-) and must start and end with lower-case alphanumeric characters (a to z and 0 to 9).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8b502e-e791-441d-8fcd-97d8fe3b8774",
   "metadata": {},
   "source": [
    "### List all objects of a specific bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2fdf82ca-412f-415f-9008-eacd64712c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your bucket \n",
    "s3_bucket = \"BUCKETNAME\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38d50cc8-9df5-46a6-a1be-b61c6609e188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_file.mp3\n",
      "creds.json\n",
      "graph.png\n",
      "requirements.txt\n"
     ]
    }
   ],
   "source": [
    "response = s3_client.list_objects_v2(Bucket=s3_bucket) \n",
    "\n",
    "if 'Contents' in response: \n",
    "    objects = response['Contents'] \n",
    "    for obj in objects: \n",
    "        print(obj['Key']) \n",
    "else: \n",
    "   print(\"The bucket is empty or the list operation failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2b72b-1e27-40a6-a9f9-8aec285974ef",
   "metadata": {},
   "source": [
    "`response['Contents']` contains information in addition to file names (last updated date, object size, ...). We can display them all in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cc33f866-54cc-4da1-ba79-5c69c3739e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>ETag</th>\n",
       "      <th>Size</th>\n",
       "      <th>StorageClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_file.mp3</td>\n",
       "      <td>2023-08-21 15:10:15+00:00</td>\n",
       "      <td>\"418b1289a3efd2a601c1ab08341669f3\"</td>\n",
       "      <td>10238080</td>\n",
       "      <td>STANDARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>creds.json</td>\n",
       "      <td>2023-08-21 15:10:13+00:00</td>\n",
       "      <td>\"dbcc4da589c34842250cb8f68acdfd51\"</td>\n",
       "      <td>40</td>\n",
       "      <td>STANDARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graph.png</td>\n",
       "      <td>2023-08-21 15:10:13+00:00</td>\n",
       "      <td>\"2a6ff4af303fed461ca7704c485536ce\"</td>\n",
       "      <td>28249</td>\n",
       "      <td>STANDARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>requirements.txt</td>\n",
       "      <td>2023-08-21 15:10:15+00:00</td>\n",
       "      <td>\"c4b3351ae370ca6d30ea4d962ce81c8d\"</td>\n",
       "      <td>59</td>\n",
       "      <td>STANDARD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Key              LastModified  \\\n",
       "0    audio_file.mp3 2023-08-21 15:10:15+00:00   \n",
       "1        creds.json 2023-08-21 15:10:13+00:00   \n",
       "2         graph.png 2023-08-21 15:10:13+00:00   \n",
       "3  requirements.txt 2023-08-21 15:10:15+00:00   \n",
       "\n",
       "                                 ETag      Size StorageClass  \n",
       "0  \"418b1289a3efd2a601c1ab08341669f3\"  10238080     STANDARD  \n",
       "1  \"dbcc4da589c34842250cb8f68acdfd51\"        40     STANDARD  \n",
       "2  \"2a6ff4af303fed461ca7704c485536ce\"     28249     STANDARD  \n",
       "3  \"c4b3351ae370ca6d30ea4d962ce81c8d\"        59     STANDARD  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(objects)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4376f12-eaf1-487d-aa0f-2b09e31a0f24",
   "metadata": {},
   "source": [
    "### Read content from objects\n",
    "\n",
    "You can read the contents of your various objects. Let's start by reading a simple text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ff40742a-5ac9-472a-9b71-6a1bd1c1865e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaggle\n",
      "matplotlib==3.7.2\n",
      "torchvision==0.15.2\n",
      "Pillow==10.0.0\n"
     ]
    }
   ],
   "source": [
    "# TXT example\n",
    "object_key = 'requirements.txt'\n",
    "response = s3_client.get_object(Bucket=s3_bucket, Key=object_key)\n",
    "object_content = response['Body'].read().decode('utf-8')\n",
    "\n",
    "print(object_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ea730-644a-44d2-b278-6dd7c144719f",
   "metadata": {},
   "source": [
    "This can be done for any file, adapting the code to the file format required. Here is another example with a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5be84ebc-d5c1-401c-9295-761bef5f9a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'username': 'ovhcloud', 'key': 'adminkey'}\n"
     ]
    }
   ],
   "source": [
    "# json example\n",
    "object_key = 'creds.json'\n",
    "response = s3_client.get_object(Bucket=s3_bucket, Key=object_key)\n",
    "object_content = response['Body'].read().decode('utf-8')\n",
    "json_data = json.loads(object_content)\n",
    "\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ea21bf-bde2-481e-b9ea-be327ec365f5",
   "metadata": {},
   "source": [
    "### Download object from S3 bucket\n",
    "\n",
    "You can download any object from your S3 bucket into your environment. Here is how to download the `requirements.txt` file under the name `local-object.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2619187-c18b-48de-84de-3e8ff68a4d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_filename = 'requirements.txt'\n",
    "local_filename = 'local-object.txt'\n",
    "\n",
    "s3_client.download_file(s3_bucket, object_filename, local_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae5b2e-0530-46e4-b4dc-a960ac642094",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once the file is downloaded, you should see it at the root of your notebook environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da669db-be1a-4f3f-953d-0ec6abdcc30a",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We hope this example has helped you to manipulate the objects in your S3 buckets directly from the OVHcloud AI Tools products. \n",
    "\n",
    "The operations presented here are not the only possible actions. Please consult the documentation for a full list of available commands.\n",
    "\n",
    "More commands here : https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
