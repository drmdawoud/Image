{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TUTORIAL: analyze and classify sounds with AI**\n",
    "\n",
    "*A guide to analyze and classify marine mammal sounds.*\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Audio or sound classification is a technique with multiple applications in the field of AI and data science.\n",
    "\n",
    "Use cases:\n",
    "- chatbots\n",
    "- automated speech translators\n",
    "- virtual assistants\n",
    "- music genre identification \n",
    "- text-to-speech applications\n",
    "- ...\n",
    "\n",
    "Audio classifications come in many types and forms, such as classification of acoustic data, music, natural language and environmental sounds.\n",
    "\n",
    "## Objective\n",
    "\n",
    "The aim of this Notebook is to use **AI NOTEBOOKS** product to train a model to **classify marine mammal sounds**.\n",
    "\n",
    "Here, the sounds in the dataset are in `.wav` format. \n",
    "\n",
    "To use them and obtain results you have to pre-process this data by following different steps.\n",
    "\n",
    "- Analyse one of these audio recordings\n",
    "- Transform each sound file into a `.csv` file\n",
    "- Train your model from the `.csv` file\n",
    "\n",
    "**USE CASE:** [Best of Watkins Marine Mammal Sound Database](https://www.kaggle.com/shreyj1729/best-of-watkins-marine-mammal-sound-database/version/3)\n",
    "\n",
    "![](./assets/categories.png)\n",
    "\n",
    "This dataset is composed of **55 different folders** corresponding to the marine mammals. In each folder are stored several sound files of each animal.\n",
    "\n",
    "You can get more information about this dataset on this [website](https://cis.whoi.edu/science/B/whalesounds/index.cfm).\n",
    "\n",
    "The data distribution is as follows:\n",
    "\n",
    "![](./assets/data.png)\n",
    "\n",
    "#### ⚠️ *For this example, we choose only the first 45 classes (or folders).*\n",
    "\n",
    "Let’s follow the different steps!\n",
    "\n",
    "![](./assets/plan.png)\n",
    "\n",
    "\n",
    "## Step 1 - Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio libraries\n",
    "import librosa\n",
    "import librosa.display as lplt\n",
    "import IPython\n",
    "\n",
    "# import matplotlib to be able to display graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# transform .wav into .csv\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# model\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Audio libraries\n",
    "\n",
    "### 1. Loading an audio file with Librosa\n",
    "\n",
    "**Librosa**: Python module for audio signal analysis. \n",
    "\n",
    "By using **Librosa**, you can extract key features from the audio samples:\n",
    "- Tempo\n",
    "- Chroma Energy Normalized\n",
    "- Mel-Freqency Cepstral Coefficients\n",
    "- Spectral Centroid, Spectral Contrast \n",
    "- Spectral Rolloff\n",
    "- Zero Crossing Rate\n",
    "\n",
    "If you want to know more about this library, refer to the [documentation](https://librosa.org/doc/latest/index.html).\n",
    "\n",
    "You can start by looking at your data by displaying different parameters using the **Librosa** library.\n",
    "\n",
    "First, you can do a test on a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sound = \"/workspace/data/AtlanticSpottedDolphin/61025001.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads and decodes the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sr = librosa.load(test_sound)\n",
    "print(type(data), type(sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.load(test_sound ,sr = 45600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Playing Audio with IPython.display.Audio\n",
    "\n",
    "[IPython.display.Audio](https://ipython.org/ipython-doc/stable/api/generated/IPython.display.html#IPython.display.Audio) advises you play audio directly in a **Jupyter notebook**.\n",
    "\n",
    "Using **IPython.display.Audio** to play the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data, rate = sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Visualizing Audio\n",
    "\n",
    "### 1. Waveforms\n",
    "\n",
    "**Waveforms**: visual representations of sound as time on the x-axis and amplitude on the y-axis. They allow for quick analysis of audio data.\n",
    "\n",
    "You can display the audio array using **librosa.display.waveplot**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show(librosa.display.waveplot(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Spectrograms\n",
    "\n",
    "**Spectrogram**: visual way of representing the intensity of a signal over time at various frequencies present in a particular waveform.\n",
    "> Some warnings can appear, don't be afraid, you can execute the next steps of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft = librosa.stft(data)\n",
    "plt.colorbar(librosa.display.specshow(stft, sr = sr, x_axis = 'time', y_axis = 'hz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_db = librosa.amplitude_to_db(abs(stft))\n",
    "plt.colorbar(librosa.display.specshow(stft_db, sr = sr, x_axis = 'time', y_axis = 'hz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Spectral Rolloff\n",
    "\n",
    "**Spectral Rolloff**: frequency below which a specified percentage of the total spectral energy.\n",
    "\n",
    "**librosa.feature.spectral_rolloff** calculates the attenuation frequency for each frame of a signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_rolloff = librosa.feature.spectral_rolloff(data + 0.01, sr = sr)[0]\n",
    "plt.show(librosa.display.waveplot(data, sr = sr, alpha = 0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Chroma Feature\n",
    "\n",
    "This tool is perfect for analyzing musical features whose pitches can be meaningfully categorized and whose tuning is close to the equal temperament scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = librosa.feature.chroma_stft(data, sr = sr)\n",
    "lplt.specshow(chroma, sr = sr, x_axis = \"time\" ,y_axis = \"chroma\", cmap = \"coolwarm\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Chroma Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Zero Crossing Rate\n",
    "\n",
    "**Zero crossing**: occurs if successive samples have different algebraic signs.\n",
    "\n",
    "- The rate at which zero crossings occur is a simple measure of the frequency content of a signal.\n",
    "- The number of zero-crossings measures the number of times in a time interval that the amplitude of speech signals passes through a zero value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1000\n",
    "end = 1200\n",
    "plt.plot(data[start:end])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Data preprocessing\n",
    "\n",
    "### 1. Data transformation\n",
    "\n",
    "To train your model, preprocessing of data is required. First of all, you have to convert the `.wav` into a `.csv` file.\n",
    "\n",
    "- Define columns name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"filename length chroma_stft_mean chroma_stft_var rms_mean rms_var spectral_centroid_mean spectral_centroid_var spectral_bandwidth_mean \\\n",
    "        spectral_bandwidth_var rolloff_mean rolloff_var zero_crossing_rate_mean zero_crossing_rate_var harmony_mean harmony_var perceptr_mean \\\n",
    "        perceptr_var tempo mfcc1_mean mfcc1_var mfcc2_mean mfcc2_var mfcc3_mean mfcc3_var mfcc4_mean mfcc4_var label\".split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create the `data.csv` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"/workspace/data/csv/data.csv\", \"w\", newline = \"\")\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define character string of marine mammals (45):\n",
    "\n",
    "There are 45 different marine animals, or 45 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marine_mammals = \"AtlanticSpottedDolphin BeardedSeal Beluga_WhiteWhale BlueWhale BottlenoseDolphin Boutu_AmazonRiverDolphin BowheadWhale ClymeneDolphin \\\n",
    "        Commerson'sDolphin CommonDolphin Dall'sPorpoise DuskyDolphin FalseKillerWhale Fin_FinbackWhale FinlessPorpoise Fraser'sDolphin Grampus_Risso'sDolphin \\\n",
    "        GraySeal GrayWhale HarborPorpoise HarbourSeal HarpSeal Heaviside'sDolphin HoodedSeal HumpbackWhale IrawaddyDolphin JuanFernandezFurSeal KillerWhale \\\n",
    "        LeopardSeal Long_FinnedPilotWhale LongBeaked(Pacific)CommonDolphin MelonHeadedWhale MinkeWhale Narwhal NewZealandFurSeal NorthernRightWhale \\\n",
    "        PantropicalSpottedDolphin RibbonSeal RingedSeal RossSeal Rough_ToothedDolphin SeaOtter Short_Finned(Pacific)PilotWhale SouthernRightWhale SpermWhale\".split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transform each `.wav` file into a `.csv` row:\n",
    "> Some warnings can appear, don't be afraid, you can execute the next steps of the notebook\n",
    ">\n",
    "> This step can be very long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for animal in marine_mammals:\n",
    "\n",
    "    for filename in os.listdir(f\"/workspace/data/{animal}/\"):\n",
    "\n",
    "        sound_name = f\"/workspace/data/{animal}/{filename}\"\n",
    "        y, sr = librosa.load(sound_name, mono = True, duration = 30)\n",
    "        chroma_stft = librosa.feature.chroma_stft(y = y, sr = sr)\n",
    "        rmse = librosa.feature.rms(y = y)\n",
    "        spec_cent = librosa.feature.spectral_centroid(y = y, sr = sr)\n",
    "        spec_bw = librosa.feature.spectral_bandwidth(y = y, sr = sr)\n",
    "        rolloff = librosa.feature.spectral_rolloff(y = y, sr = sr)\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)\n",
    "        mfcc = librosa.feature.mfcc(y = y, sr = sr)\n",
    "        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "\n",
    "        for e in mfcc:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "\n",
    "        to_append += f' {animal}'\n",
    "        file = open('/workspace/data/csv/data.csv', 'a', newline = '')\n",
    "\n",
    "        with file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the `data.csv` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/workspace/data/csv/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Features extraction\n",
    "\n",
    "In the preprocessing of the data, **feature extraction** is necessary before running the training. The purpose is to define the **inputs** and **outputs** of the neural network.\n",
    "\n",
    "- **OUTPUT** (y): last column which is the `label`.\n",
    "\n",
    "You cannot use text directly for training. You have encode these labels with the **LabelEncoder()** function of **sklearn.preprocessing**.\n",
    "\n",
    "So, before running run a model, convert this type of categorical text data into numerical data that the model can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = df.iloc[:,-1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(class_list)\n",
    "print(\"y: \", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **INPUTS** (X): all other columns are input parameters of the neural network except the `filename`.\n",
    "\n",
    "You remove the first column which does not provide any information for the training (the filename) and the last one which corresponds to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_parameters = df.iloc[:, 1:27]\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(input_parameters))\n",
    "print(\"X:\", X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Split dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Building the model\n",
    "\n",
    "The first step is to build the model and display the summary.\n",
    "\n",
    "For the CNN model, all hidden layers use a **ReLU** activation function, the output layer a **Softmax** function and a **Dropout** is used to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(512, activation = 'relu', input_shape = (X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(256, activation = 'relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(45, activation = 'softmax'),\n",
    "])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Model training and evaluation\n",
    "\n",
    "**Adam** optimizer is used to train the model over 100 epochs. This choice was made because it allows us to obtain better results.\n",
    "\n",
    "The loss is calculated with the **sparse_categorical_crossentropy** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model,epochs, optimizer):\n",
    "    batch_size = 128\n",
    "    model.compile(optimizer = optimizer, loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n",
    "    return model.fit(X_train, y_train, validation_data = (X_val, y_val), epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can launch the training!\n",
    "> This step can be very long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = trainModel(model = model, epochs = 100, optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display **loss** curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_curve = model_history.history[\"loss\"]\n",
    "loss_val_curve = model_history.history[\"val_loss\"]\n",
    "plt.plot(loss_train_curve, label = \"Train\")\n",
    "plt.plot(loss_val_curve, label = \"Validation\")\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display **accuracy** curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_curve = model_history.history[\"accuracy\"]\n",
    "acc_val_curve = model_history.history[\"val_accuracy\"]\n",
    "plt.plot(acc_train_curve, label = \"Train\")\n",
    "plt.plot(acc_val_curve, label = \"Validation\")\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_val, y_val, batch_size = 128)\n",
    "print(\"The test loss is: \", test_loss)\n",
    "print(\"The best accuracy is: \", test_acc*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 - Make predictions on test data\n",
    "\n",
    "To test your model and predict which classes new sounds belong to, you can import sounds into a `/workspace/data_test` folder. \n",
    "\n",
    "Here we are testing **2 new sounds**.\n",
    "\n",
    "### 1. Test data preprocessing\n",
    "\n",
    "To test your model, preprocessing of data is also required.\n",
    "\n",
    "- Define columns name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header => for test data, we remove the columns \"filename\" and \"label\"\n",
    "header_test = \"filename length chroma_stft_mean chroma_stft_var rms_mean rms_var spectral_centroid_mean spectral_centroid_var spectral_bandwidth_mean \\\n",
    "        spectral_bandwidth_var rolloff_mean rolloff_var zero_crossing_rate_mean zero_crossing_rate_var harmony_mean harmony_var perceptr_mean perceptr_var tempo mfcc1_mean mfcc1_var mfcc2_mean \\\n",
    "        mfcc2_var mfcc3_mean mfcc3_var mfcc4_mean mfcc4_var\".split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create the `data_test.csv` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/workspace/data/csv/data_test.csv', 'w', newline = '')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transform each `.wav` file into a `.csv` row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(f\"/workspace/data/data_test/\"):\n",
    "    sound_name = f\"/workspace/data/data_test/{filename}\"\n",
    "    y, sr = librosa.load(sound_name, mono = True, duration = 30)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y = y, sr = sr)\n",
    "    rmse = librosa.feature.rms(y = y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y = y, sr = sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y = y, sr = sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y = y, sr = sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y = y, sr = sr)\n",
    "    to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "\n",
    "    for e in mfcc:\n",
    "        to_append += f' {np.mean(e)}'\n",
    "\n",
    "    file = open('/workspace/data/csv/data_test.csv', 'a', newline = '')\n",
    "\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the `data_test.csv` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/workspace/data/csv/data_test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(np.array(df_test.iloc[:, 1:27]))\n",
    "print(\"X_test:\", X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for samples\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate argmax for predictions\n",
    "classes = np.argmax(predictions, axis = 1)\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform classes number into classes name\n",
    "result = encoder.inverse_transform(classes)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 - Save the model for future inference\n",
    "\n",
    "> To save your model, you should create an other Object Storage container (with write rights) and mount it in your workspace (`saved_model` in this example).\n",
    "\n",
    "You can now save your model in a dedicated folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/workspace/saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_model directory\n",
    "%ls /workspace/saved_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains an assets folder, saved_model.pb, and variables folder.\n",
    "%ls /workspace/saved_model/my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/workspace/saved_model/my_model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The accuracy of the model can be improved by increasing the number of epochs, but after a certain period we reach a threshold, so the value should be determined accordingly.\n",
    "\n",
    "The accuracy obtained for the test set is **93.71 %**, which is a satisfactory result.\n",
    "\n",
    "#### *I hope you have enjoyed this tutorial. Try for yourself!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
